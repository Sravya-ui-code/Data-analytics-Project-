{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exam description\n",
    "For this exam, you will predict the target values for the test.csv. \n",
    "\n",
    "#### Your task:\n",
    "find a good machine learning model to predict the target value. Then predict the target values of the instances in the test.csv. \n",
    "\n",
    "#### Exam rules\n",
    "- You can use only the machine learning models discussed in this course. \n",
    "    - If the prediction is based on a model that is not discussed in class, one of the models in your submission will randomly be selected for grading. \n",
    "- Fifty percent of the grade is based on your Python code submission. The other 50 percent of your grade is based on the evaluation score of the prediction. \n",
    "- The exam should be syntax error-free. Run your code before the final submission. \n",
    "- Save the final prediction array as ``final_test_prediction``. \n",
    "- <font color = 'red'> The final prediction will be evaluated using the **roc_auc_score** function. </font>\n",
    "\n",
    "#### Devliverable\n",
    "Submit ONLY the iPython notebook or the .py file of your work. Use the following frame for your submission. Please don't remove the headers in the following structure. \n",
    "\n",
    "#### Rubric\n",
    "| Descriptio | Fair | Good | excelent |\n",
    "|:-----------|:------|:------|:----------|\n",
    "|Preprocessing|Demonstrate limited understanding of preprocessing steps | Demonstrate a moderate ability to find a way to apply the preprocessing step to prepare the dataset for Machine learning models | Demonstrate the ability to choose the appropriate preprocessing model to prepare the dataset |\n",
    "|Machine learning model | Demonstrate limited understanding of methods used to train machine learning models | Demonstrate the ability to understand techniques used to train machine learning models with some effectiveness. This includes optimization algorithms, initialization, regularization, and hyperparameter search methods | Demonstrate ability to understand and apply various algorithms as well as initialization, regularization, and hyperparameter search methods |\n",
    "|Final prediction |Demonstrate limited understanding of strategies to structure and end to end machine learning project | Demonstrate ability to understand classic ML strategies such as error analysis, data split, data collection and evaluation metric selection with some effectiveness | Demonstrates ability to structure the project and apply methods such as error analysis, data split, data collection, design a labeling process and select proper evaluation metrics to improve performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the <b> train </b> and the <b> test </b> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "df1 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\"'\",\"\")\n",
    "df1.columns = df1.columns.str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['$1000 Damage to Any One Persons Property', 'Bridge Detail',\n",
       "       'Construction Zone Flag', 'Construction Zone Workers Present Flag',\n",
       "       'Crash Time', 'Day of Week', 'Highway System',\n",
       "       'Intersecting Highway Number', 'Intersecting Street Name',\n",
       "       'Manner of Collision', 'Median Type', 'Median Width',\n",
       "       'Number of Entering Roads', 'Number of Lanes', 'Surface Condition',\n",
       "       'Surface Type', 'Surface Width', 'Weather Condition', 'Crash Severity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analysing the data we find that there are total 2322 Instances and 19 features. We need to predict if the severity of the crash is serious or not serious. This is a binary classification problem. The data is highly imbalanced with more than 98% of the data with the crash severity - 'Not Serious'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ``train.csv`` (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Crash Time </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the time to hh:mm and then divide the time into morning and night. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['Crash Time'].astype(str)\n",
    "time = [f'{t[:-2]}:{t[-2:]}' for t in time ]\n",
    "\n",
    "#time = time[0:]\n",
    "#print(time[0:3])\n",
    "for i in range(0,len(time)):\n",
    "    a = time[i].split(\":\")\n",
    "    if len(time[i]) <= 3:\n",
    "        time[i] = 'Night'\n",
    "    else:\n",
    "        if int(a[0]) <= 6:\n",
    "            time[i] = 'Night'\n",
    "\n",
    "        elif int(a[0]) >= 6 and int(a[0]) <= 18:\n",
    "            time[i] = 'Morning'\n",
    "        elif int(a[0]) > 18 and int(a[0]) < 24:\n",
    "            time[i] = 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crash Time'] = time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crash Time'] = df['Crash Time'].replace({'Morning': 1,'Night' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>      Crash Severity   </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dependent variable to a binary numeric value \n",
    "\n",
    "Map 1 to ' Not Serious'  &   Map 0 to 'Serious'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not serious    2286\n",
       "Serious          36\n",
       "Name: Crash Severity, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crash Severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crash Severity'] = df['Crash Severity'].replace({'Not serious': 1,'Serious' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> $1000 Damage to Any One Persons Property </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column - '$1000 Damage to Any One Persons Property' has two values yes and no.\n",
    "\n",
    "Since the majority of the values are 'Yes' Lets replace yes with 1 and No with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['$1000 Damage to Any One Persons Property'] = df['$1000 Damage to Any One Persons Property'].replace({'Yes': 1,'No' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Day of Week </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables for the Day of the week column : Since ' Week day' is a nominal variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df['Day of Week'], prefix= 'Day of Week')\n",
    "df[cols.columns] = cols\n",
    "df.drop('Day of Week', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Construction Zone Flag </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Construction Zone Flag' has two values yes and no.\n",
    "\n",
    "Since the majority of the values are 'No'. Lets replace yes with 0 and No with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Construction Zone Flag'] = df['Construction Zone Flag'].replace({'No': 1,'Yes' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Construction Zone Workers Present Flag </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Construction Zone Workers Present Flag' has two values yes and no.\n",
    "\n",
    "Since the majority of the values are 'No'.\n",
    "\n",
    "Lets replace yes with 0 and No with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Construction Zone Workers Present Flag'] = df['Construction Zone Workers Present Flag'].replace({'No': 1,'Yes' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Surface Type </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface type has the value no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Surface Type', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Highway system </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highway system has only one type of data. So we don't get any information for further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Highway System', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Bridge detail </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bridge detail has more than like 90% of the data as 'Not Applicable'. So we dont get much information creating dummies for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Bridge Detail', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Median Type </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Type has more than like 90% of the data as 'No Data'. So we dont get much information creating dummies for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Median Type', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Weather Condition </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created dummies for the categorical variable Weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 - CLEAR                            1817\n",
       "2 - CLOUDY                            319\n",
       "3 - RAIN                              179\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)       2\n",
       "6 - FOG                                 2\n",
       "5 - SNOW                                1\n",
       "99 - UNKNOWN                            1\n",
       "4 - SLEET/HAIL                          1\n",
       "Name: Weather Condition, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weather Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weather Condition'] = df['Weather Condition'].replace({'99 - UNKNOWN': '1 - CLEAR'})\n",
    "df['Weather Condition'] = df['Weather Condition'].replace({'5 - SNOW': '1 - CLEAR'})\n",
    "df['Weather Condition'] = df['Weather Condition'].replace({'4 - SLEET/HAIL': '1 - CLEAR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 - CLEAR                            1820\n",
       "2 - CLOUDY                            319\n",
       "3 - RAIN                              179\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)       2\n",
       "6 - FOG                                 2\n",
       "Name: Weather Condition, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weather Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df['Weather Condition'], prefix= 'Weather Condition')\n",
    "df[cols.columns] = cols\n",
    "df.drop('Weather Condition', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Surface condition</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created dummies for the surface condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Surface Condition'] = df['Surface Condition'].replace({'99 - UNKNOWN': '1 - DRY'})\n",
    "df['Surface Condition'] = df['Surface Condition'].replace({'7 - SAND, MUD, DIRT': '1 - DRY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 - DRY                              2055\n",
       "2 - WET                               246\n",
       "3 - STANDING WATER                     14\n",
       "6 - ICE                                 5\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)       2\n",
       "Name: Surface Condition, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Surface Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df['Surface Condition'], prefix= 'Surface Condition')\n",
    "df[cols.columns] = cols\n",
    "df.drop('Surface Condition', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Intersecting Highway Number </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Data    1948\n",
       "35          221\n",
       "345         146\n",
       "75            7\n",
       "Name: Intersecting Highway Number, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Intersecting Highway Number'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the column - Intersecting highway number there are around 1948 values with no data. This is more than 80% of the data in that column. It makes no sense to impute it with median or the mode values.I have removed this column from the dataset because it wont be much informative later during analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Intersecting Highway Number', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Median Width </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median width we have around 1801 values of 40 and 521 values with no data.\n",
    "I have dropped the variable since values of one type dont give any importance after further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Median Width', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>  Manner of Collision    </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different 'Manner of collision' which are unordered and categorical so I have created dummies for this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAME DIRECTION - BOTH GOING STRAIGHT-REAR END        665\n",
       "SAME DIRECTION - BOTH GOING STRAIGHT-SIDESWIPE       542\n",
       "SAME DIRECTION - ONE STRAIGHT-ONE STOPPED            404\n",
       "ONE MOTOR VEHICLE - GOING STRAIGHT                   325\n",
       "ANGLE - BOTH GOING STRAIGHT                          177\n",
       "OPPOSITE DIRECTION - ONE STRAIGHT-ONE LEFT TURN       89\n",
       "SAME DIRECTION - ONE STRAIGHT-ONE LEFT TURN           32\n",
       "ANGLE - ONE STRAIGHT-ONE RIGHT TURN                   16\n",
       "SAME DIRECTION - ONE STRAIGHT-ONE RIGHT TURN          12\n",
       "SAME DIRECTION - BOTH RIGHT TURN                       9\n",
       "OPPOSITE DIRECTION - ONE STRAIGHT-ONE BACKING          9\n",
       "ONE MOTOR VEHICLE - TURNING RIGHT                      9\n",
       "ANGLE - ONE STRAIGHT-ONE LEFT TURN                     8\n",
       "OPPOSITE DIRECTION - ONE BACKING-ONE STOPPED           7\n",
       "ONE MOTOR VEHICLE - TURNING LEFT                       7\n",
       "ONE MOTOR VEHICLE - OTHER                              2\n",
       "ANGLE - ONE STRAIGHT-ONE STOPPED                       2\n",
       "OPPOSITE DIRECTION - ONE RIGHT TURN-ONE LEFT TURN      1\n",
       "SAME DIRECTION - BOTH LEFT TURN                        1\n",
       "ANGLE - ONE RIGHT TURN-ONE STOPPED                     1\n",
       "ANGLE - ONE STRAIGHT-ONE BACKING                       1\n",
       "OPPOSITE DIRECTION - BOTH GOING STRAIGHT               1\n",
       "ONE MOTOR VEHICLE - BACKING                            1\n",
       "OPPOSITE DIRECTION - ONE LEFT TURN-ONE STOPPED         1\n",
       "Name: Manner of Collision, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Manner of Collision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - BOTH GOING STRAIGHT-REAR END' : 'SAME DIRECTION'})\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - BOTH GOING STRAIGHT-SIDESWIPE': 'SAME DIRECTION'})\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - ONE STRAIGHT-ONE STOPPED' : 'SAME DIRECTION'})\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - ONE STRAIGHT-ONE LEFT TURN' : 'SAME DIRECTION'})\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - ONE STRAIGHT-ONE RIGHT TURN' : 'SAME DIRECTION'})\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - BOTH RIGHT TURN' : 'SAME DIRECTION' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'SAME DIRECTION - BOTH LEFT TURN' :'SAME DIRECTION' })\n",
    "\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - GOING STRAIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING RIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING LEFT' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - OTHER' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ANGLE - BOTH GOING STRAIGHT' :'ANGLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE RIGHT TURN' :'ANGLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE LEFT TURN' :'ANGLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE STOPPED' :'ANGLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ANGLE - ONE RIGHT TURN-ONE STOPPED' :'ANGLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE BACKING' :'ANGLE' })\n",
    "\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - GOING STRAIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING RIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING LEFT' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - OTHER' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "\n",
    "\n",
    "\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE STRAIGHT-ONE LEFT TURN' :'OPPOSITE DIRECTION' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE STRAIGHT-ONE BACKING' :'OPPOSITE DIRECTION' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE BACKING-ONE STOPPED' :'OPPOSITE DIRECTION' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE LEFT TURN-ONE STOPPED' :'OPPOSITE DIRECTION' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE RIGHT TURN-ONE LEFT TURN' :'OPPOSITE DIRECTION' })\n",
    "df['Manner of Collision'] = df['Manner of Collision'].replace({'OPPOSITE DIRECTION - BOTH GOING STRAIGHT' :'OPPOSITE DIRECTION' })\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAME DIRECTION        1665\n",
       "ONE MOTOR VEHICLE      344\n",
       "ANGLE                  205\n",
       "OPPOSITE DIRECTION     108\n",
       "Name: Manner of Collision, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Manner of Collision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df['Manner of Collision'], prefix= 'Manner of Collision')\n",
    "df[cols.columns] = cols\n",
    "df.drop('Manner of Collision', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Intersecting Street Name  </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are just 541 values out of 2322. So changing to dummies doesn't make any sense. It is wiser to remove this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Intersecting Street Name', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>    Number of Entering Roads   </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97 - NOT APPLICABLE                  1980\n",
       "4 - FOUR ENTERING ROADS               193\n",
       "2 - THREE ENTERING ROADS - T           68\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)      44\n",
       "3 - THREE ENTERING ROADS - Y           31\n",
       "8 - CLOVERLEAF                          2\n",
       "6 - SIX ENTERING ROADS                  2\n",
       "5 - FIVE ENTERING ROADS                 2\n",
       "Name: Number of Entering Roads, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Number of Entering Roads'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Entering Roads'] = df['Number of Entering Roads'].replace({'5 - FIVE ENTERING ROADS': '97 - NOT APPLICABLE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97 - NOT APPLICABLE                  1982\n",
       "4 - FOUR ENTERING ROADS               193\n",
       "2 - THREE ENTERING ROADS - T           68\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)      44\n",
       "3 - THREE ENTERING ROADS - Y           31\n",
       "8 - CLOVERLEAF                          2\n",
       "6 - SIX ENTERING ROADS                  2\n",
       "Name: Number of Entering Roads, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Number of Entering Roads'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dummies for the number of entering roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df['Number of Entering Roads'], prefix= 'Number of Entering Roads')\n",
    "df[cols.columns] = cols\n",
    "df.drop('Number of Entering Roads', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Lanes    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the number of lanes column the 'No Data' has no importance. We can replace 'No Data' with the highest value. Then we can map to 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8          1257\n",
       "6           544\n",
       "No Data     521\n",
       "Name: Number of Lanes, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Number of Lanes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Lanes'] = df['Number of Lanes'].replace({'No Data': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Lanes'] = df['Number of Lanes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    1778\n",
       "6     544\n",
       "Name: Number of Lanes, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Number of Lanes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Lanes']=df['Number of Lanes'].map({8:1,6:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>   Surface Width   </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96         1257\n",
       "72          544\n",
       "No Data     521\n",
       "Name: Surface Width, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Surface Width'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Surface Width'] = df['Surface Width'].replace({'No Data': 96})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Surface Width'] = df['Surface Width'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surface Width\"]=df[\"Surface Width\"].map({96:1,72:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1778\n",
       "0     544\n",
       "Name: Surface Width, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Surface Width'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ``test.csv`` (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used the same steps for the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['$1000 Damage to Any One Persons Property'] = df1['$1000 Damage to Any One Persons Property'].replace({'Yes': 1,'No' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df1['Day of Week'], prefix= 'Day of Week')\n",
    "df1[cols.columns] = cols\n",
    "df1.drop('Day of Week', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Construction Zone Flag'] = df1['Construction Zone Flag'].replace({'No': 1,'Yes' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Construction Zone Workers Present Flag'] = df1['Construction Zone Workers Present Flag'].replace({'No': 1,'Yes' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Surface Type', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Highway System', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Bridge Detail', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Median Type', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df1['Weather Condition'], prefix= 'Weather Condition')\n",
    "df1[cols.columns] = cols\n",
    "df1.drop('Weather Condition', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df1['Surface Condition'], prefix= 'Surface Condition')\n",
    "df1[cols.columns] = cols\n",
    "df1.drop('Surface Condition', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Data    657\n",
       "35          71\n",
       "345         41\n",
       "75           5\n",
       "Name: Intersecting Highway Number, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Intersecting Highway Number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Intersecting Highway Number', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['Median Width'] = df1['Median Width'].replace({'40':1 , 'No Data':0})\n",
    "df1 = df1.drop('Median Width', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAME DIRECTION - BOTH GOING STRAIGHT-SIDESWIPE       203\n",
       "SAME DIRECTION - BOTH GOING STRAIGHT-REAR END        202\n",
       "SAME DIRECTION - ONE STRAIGHT-ONE STOPPED            142\n",
       "ONE MOTOR VEHICLE - GOING STRAIGHT                   101\n",
       "ANGLE - BOTH GOING STRAIGHT                           58\n",
       "OPPOSITE DIRECTION - ONE STRAIGHT-ONE LEFT TURN       27\n",
       "ANGLE - ONE STRAIGHT-ONE RIGHT TURN                    9\n",
       "SAME DIRECTION - ONE STRAIGHT-ONE RIGHT TURN           8\n",
       "SAME DIRECTION - ONE STRAIGHT-ONE LEFT TURN            5\n",
       "ONE MOTOR VEHICLE - TURNING LEFT                       4\n",
       "ONE MOTOR VEHICLE - TURNING RIGHT                      2\n",
       "ANGLE - ONE STRAIGHT-ONE LEFT TURN                     2\n",
       "OPPOSITE DIRECTION - BOTH GOING STRAIGHT               2\n",
       "ANGLE - ONE LEFT TURN-ONE STOPPED                      1\n",
       "OTHER                                                  1\n",
       "OPPOSITE DIRECTION - ONE RIGHT TURN-ONE LEFT TURN      1\n",
       "OPPOSITE DIRECTION - ONE BACKING-ONE STOPPED           1\n",
       "ONE MOTOR VEHICLE - BACKING                            1\n",
       "SAME DIRECTION - BOTH LEFT TURN                        1\n",
       "ANGLE - ONE STRAIGHT-ONE BACKING                       1\n",
       "ONE MOTOR VEHICLE - OTHER                              1\n",
       "SAME DIRECTION - BOTH RIGHT TURN                       1\n",
       "Name: Manner of Collision, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Manner of Collision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - BOTH GOING STRAIGHT-REAR END' : 'SAME DIRECTION'})\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - BOTH GOING STRAIGHT-SIDESWIPE': 'SAME DIRECTION'})\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - ONE STRAIGHT-ONE STOPPED' : 'SAME DIRECTION'})\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - ONE STRAIGHT-ONE LEFT TURN' : 'SAME DIRECTION'})\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - ONE STRAIGHT-ONE RIGHT TURN' : 'SAME DIRECTION'})\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - BOTH RIGHT TURN' : 'SAME DIRECTION' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'SAME DIRECTION - BOTH LEFT TURN' :'SAME DIRECTION' })\n",
    "\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - GOING STRAIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING RIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING LEFT' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - OTHER' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - BOTH GOING STRAIGHT' :'ANGLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE RIGHT TURN' :'ANGLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE LEFT TURN' :'ANGLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE STOPPED' :'ANGLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - ONE RIGHT TURN-ONE STOPPED' :'ANGLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - ONE STRAIGHT-ONE BACKING' :'ANGLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ANGLE - ONE LEFT TURN-ONE STOPPED' :'ANGLE' })\n",
    "\n",
    "\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - GOING STRAIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING RIGHT' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - TURNING LEFT' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - OTHER' :'ONE MOTOR VEHICLE' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'ONE MOTOR VEHICLE - BACKING' :'ONE MOTOR VEHICLE' })\n",
    "\n",
    "\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE STRAIGHT-ONE LEFT TURN' :'OPPOSITE DIRECTION' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE STRAIGHT-ONE BACKING' :'OPPOSITE DIRECTION' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE BACKING-ONE STOPPED' :'OPPOSITE DIRECTION' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE LEFT TURN-ONE STOPPED' :'OPPOSITE DIRECTION' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OPPOSITE DIRECTION - ONE RIGHT TURN-ONE LEFT TURN' :'OPPOSITE DIRECTION' })\n",
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OPPOSITE DIRECTION - BOTH GOING STRAIGHT' :'OPPOSITE DIRECTION' })\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Manner of Collision'] = df1['Manner of Collision'].replace({'OTHER' :'SAME DIRECTION' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAME DIRECTION        563\n",
       "ONE MOTOR VEHICLE     109\n",
       "ANGLE                  71\n",
       "OPPOSITE DIRECTION     31\n",
       "Name: Manner of Collision, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Manner of Collision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df1['Manner of Collision'], prefix= 'Manner of Collision')\n",
    "df1[cols.columns] = cols\n",
    "df1.drop('Manner of Collision', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Intersecting Street Name', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97 - NOT APPLICABLE                  670\n",
       "4 - FOUR ENTERING ROADS               62\n",
       "2 - THREE ENTERING ROADS - T          19\n",
       "3 - THREE ENTERING ROADS - Y          14\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)      6\n",
       "7 - TRAFFIC CIRCLE                     1\n",
       "8 - CLOVERLEAF                         1\n",
       "6 - SIX ENTERING ROADS                 1\n",
       "Name: Number of Entering Roads, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Number of Entering Roads'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Number of Entering Roads'] = df1['Number of Entering Roads'].replace({'7 - TRAFFIC CIRCLE': '97 - NOT APPLICABLE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97 - NOT APPLICABLE                  671\n",
       "4 - FOUR ENTERING ROADS               62\n",
       "2 - THREE ENTERING ROADS - T          19\n",
       "3 - THREE ENTERING ROADS - Y          14\n",
       "98 - OTHER (EXPLAIN IN NARRATIVE)      6\n",
       "8 - CLOVERLEAF                         1\n",
       "6 - SIX ENTERING ROADS                 1\n",
       "Name: Number of Entering Roads, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Number of Entering Roads'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df1['Number of Entering Roads'], prefix= 'Number of Entering Roads')\n",
    "df1[cols.columns] = cols\n",
    "df1.drop('Number of Entering Roads', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Number of Lanes'] = df1['Number of Lanes'].replace({'No Data': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Number of Lanes'] = df1['Number of Lanes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Number of Lanes']=df1['Number of Lanes'].map({8:1,6:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Surface Width'] = df1['Surface Width'].replace({'No Data': 96})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Surface Width'] = df1['Surface Width'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Surface Width\"]=df1[\"Surface Width\"].map({96:1,72:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df1['Crash Time'].astype(str)\n",
    "time = [f'{t[:-2]}:{t[-2:]}' for t in time ]\n",
    "\n",
    "#time = time[0:]\n",
    "#print(time[0:3])\n",
    "for i in range(0,len(time)):\n",
    "    a = time[i].split(\":\")\n",
    "    if len(time[i]) <= 3:\n",
    "        time[i] = 'Night'\n",
    "    else:\n",
    "        if int(a[0]) <= 6:\n",
    "            time[i] = 'Night'\n",
    "\n",
    "        elif int(a[0]) >= 6 and int(a[0]) <= 18:\n",
    "            time[i] = 'Morning'\n",
    "        elif int(a[0]) > 18 and int(a[0]) < 24:\n",
    "            time[i] = 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Crash Time'] = time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Crash Time'] = df1['Crash Time'].replace({'Morning': 1,'Night' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is highly imbalanced.We need to upsample the data inorder to get accurate prediictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\saisr\\anaconda\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\saisr\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\saisr\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\saisr\\anaconda\\lib\\site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\saisr\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saisr\\anaconda\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Crash Severity']\n",
    "X = df.drop('Crash Severity', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is highly imbalanced I am not able to predict accurate results through normal modelling. Inorder to get good prediction results I have done the upsampling using SMOTE and used Stratified Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "def upsample_SMOTE(X_train, y_train, ratio=1.0):\n",
    "    \"\"\"Upsamples minority class using SMOTE.\n",
    "    Ratio argument is the percentage of the upsampled minority class in relation\n",
    "    to the majority class. Default is 1.0\n",
    "    \"\"\"\n",
    "    sm = SMOTE(random_state=23, sampling_strategy=ratio)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    #print(len(X_train_sm), len(y_train_sm))\n",
    "    return X_train_sm, y_train_sm\n",
    "\n",
    "X_train_sm,y_train_sm = upsample_SMOTE(X_train, y_train, ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "sk =StratifiedKFold(n_splits=2, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> KNN </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 12))\n",
    "param_grid = dict(n_neighbors=k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv= sk, return_train_score=True,scoring= 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 8}\n",
      "Best cross-validation score: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9504\n",
      "Test score: 0.9088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score,f1_score\n",
    "knn = KNeighborsClassifier(8)\n",
    "\n",
    "knn.fit(X_train_sm, y_train_sm)\n",
    "print('Train score: {:.4f}'.format(knn.score(X_train_sm, y_train_sm)))\n",
    "print('Test score: {:.4f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.7097902097902098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = knn.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, knn.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned Hyperparameters :(best parameters)  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "accuracy : 0.9911307660572756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "c_range=[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "grid = {\"C\": c_range , \"penalty\":[\"l1\",\"l2\"],\"solver\":[\"liblinear\"]}\n",
    "logreg = LogisticRegression(class_weight = 'balanced',max_iter = 10000)\n",
    "logreg_cv = GridSearchCV(logreg,grid,cv= sk, scoring = 'roc_auc')\n",
    "logreg_cv.fit(X_train_sm,y_train_sm)\n",
    "\n",
    "print(\"tuned Hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.954784130688448\n",
      "Test Score 0.9380378657487092\n"
     ]
    }
   ],
   "source": [
    "log_l1 = LogisticRegression(penalty = 'l2', C = 10, solver = 'liblinear', max_iter = 500, class_weight = 'balanced')\n",
    "log_l1.fit(X_train_sm, y_train_sm)\n",
    "train_score = (log_l1.score(X_train_sm, y_train_sm))\n",
    "test_score = (log_l1.score(X_test, y_test))\n",
    "print('Train Score',train_score)\n",
    "print('Test Score' ,test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6417055167055168\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_l1.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, log_l1.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC with Poly kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'degree': [1,2,3,4,5,6,7,8,9,10]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "grid_search_poly = GridSearchCV(SVC(kernel = 'poly'),param_grid, cv= sk, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=SVC(kernel='poly'),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_poly.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'degree': 3}\n",
      "Best cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search_poly.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search_poly.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.9760793465577596\n",
      "Test Score 0.9432013769363167\n"
     ]
    }
   ],
   "source": [
    "clf2 = SVC(kernel='poly', C= 10 , degree = 5,probability=True)\n",
    "clf2.fit(X_train_sm, y_train_sm)\n",
    "train_score = (clf2.score(X_train_sm, y_train_sm))\n",
    "test_score = (clf2.score(X_test, y_test))\n",
    "print('Train Score',train_score)\n",
    "print('Test Score' ,test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6712315462315462\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, clf2.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.95\n",
      "Best parameters: {'max_depth': 9, 'min_samples': 10, 'min_samples_split': 450, 'min_impurity_decrease': 0.0002}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "best_score = 0\n",
    "for max_depth in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    for min_samples_leaf in [10,25,50,100,500,1000,250,1500,2000,750]:\n",
    "        for  min_samples_split in [10,50,100,150,200,250,300,350,400,450]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "            for min_impurity_decrease in [0.0002,0.0005,0.0007,0.0009,0.001,0.003,0.005,0.007,0.009,0.01]:\n",
    "                dtree = DecisionTreeClassifier(max_depth = max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split, random_state=0)\n",
    "                dtree.fit(X_train_sm, y_train_sm)\n",
    "        # evaluate the SVC on the test set\n",
    "                score = dtree.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'max_depth': max_depth, 'min_samples': min_samples_leaf,'min_samples_split': min_samples_split, 'min_impurity_decrease':min_impurity_decrease}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Score: 0.9122203098106713 Train Score 0.8809801633605601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(max_depth = 9, min_samples_leaf = 10,min_impurity_decrease =0.0002 ,min_samples_split = 300,random_state=0)\n",
    "dtree.fit(X_train_sm, y_train_sm)\n",
    "Test_Score = dtree.score(X_test, y_test)\n",
    "Train_score = dtree.score(X_train_sm, y_train_sm)\n",
    "print('Test_Score:', Test_Score, 'Train Score',Train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.7898212898212897\n"
     ]
    }
   ],
   "source": [
    "y_pred = dtree.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, dtree.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(8)\n",
    "bag_clf = BaggingClassifier(knn ,max_samples=100, bootstrap=True, random_state=0, oob_score = True)\n",
    "\n",
    "param_grid = {'n_estimators':[100,500,1000]}\n",
    "\n",
    "bag_grid = GridSearchCV(bag_clf, param_grid = param_grid, cv = sk, n_jobs = -1, scoring = 'roc_auc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=8),\n",
       "                                         max_samples=100, oob_score=True,\n",
       "                                         random_state=0),\n",
       "             n_jobs=-1, param_grid={'n_estimators': [100, 500, 1000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_grid.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 100}\n",
      "Best cross-validation score: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(bag_grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(bag_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(knn,max_samples=100,n_estimators = 1000, bootstrap = True, random_state=0, oob_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=8),\n",
       "                  max_samples=100, n_estimators=1000, oob_score=True,\n",
       "                  random_state=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.81\n",
      "Test score: 0.65\n"
     ]
    }
   ],
   "source": [
    "print('Train score: %.2f'%bag_clf.score(X_train_sm, y_train_sm))\n",
    "print('Test score: %.2f'%bag_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.7022144522144522\n"
     ]
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, bag_clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd = RandomForestClassifier( max_depth = 9, n_estimators = 100, bootstrap= True,n_jobs=-1, random_state=0)\n",
    "\n",
    "bag_clf = BaggingClassifier(rnd,max_samples=100, bootstrap=True, random_state=0, oob_score = True)\n",
    "\n",
    "param_grid = {'n_estimators':[100,500,1000]}\n",
    "\n",
    "bag_grid = GridSearchCV(bag_clf, param_grid = param_grid, cv = sk, n_jobs = -1, scoring = 'roc_auc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=BaggingClassifier(base_estimator=RandomForestClassifier(max_depth=9,\n",
       "                                                                               n_jobs=-1,\n",
       "                                                                               random_state=0),\n",
       "                                         max_samples=100, oob_score=True,\n",
       "                                         random_state=0),\n",
       "             n_jobs=-1, param_grid={'n_estimators': [100, 500, 1000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_grid.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 1000}\n",
      "Best cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(bag_grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(bag_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(rnd,max_samples=100,n_estimators = 1000,bootstrap=True, random_state=0, oob_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(max_depth=9, n_jobs=-1,\n",
       "                                                        random_state=0),\n",
       "                  max_samples=100, n_estimators=1000, oob_score=True,\n",
       "                  random_state=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.89\n",
      "Test score: 0.83\n",
      "Out-of-bag score: 0.88\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print('Train score: %.2f'%bag_clf.score(X_train_sm, y_train_sm))\n",
    "print('Test score: %.2f'%bag_clf.score(X_test, y_test))\n",
    "print('Out-of-bag score: %.2f'%bag_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6865773115773115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, bag_clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasting with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(8)\n",
    "bag_clf = BaggingClassifier(knn ,max_samples=100, bootstrap= False, random_state=0)\n",
    "\n",
    "param_grid = {'n_estimators':[100,500,1000]}\n",
    "\n",
    "bag_grid = GridSearchCV(bag_clf, param_grid = param_grid, cv = sk, n_jobs = -1, scoring = 'roc_auc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=8),\n",
       "                                         bootstrap=False, max_samples=100,\n",
       "                                         random_state=0),\n",
       "             n_jobs=-1, param_grid={'n_estimators': [100, 500, 1000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_grid.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 1000}\n",
      "Best cross-validation score: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(bag_grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(bag_grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(knn,max_samples=100,n_estimators = 1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=8),\n",
       "                  max_samples=100, n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.81\n",
      "Test score: 0.65\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print('Train score: %.2f'%bag_clf.score(X_train_sm, y_train_sm))\n",
    "print('Test score: %.2f'%bag_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.7022144522144522\n"
     ]
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, bag_clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_estimators': [100, 250, 350, 400, 500, 1000, 750]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {'max_depth': [1,2,3,4,5,6,7,8,9],\n",
    "              'n_estimators': [100,250,350,400,500,1000,750]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search_poly = GridSearchCV(RandomForestClassifier(bootstrap= True,n_jobs=-1, random_state=0),param_grid, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1, random_state=0),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'n_estimators': [100, 250, 350, 400, 500, 1000, 750]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_poly.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 9, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search_poly.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search_poly.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = RandomForestClassifier( max_depth = 9, n_estimators = 100, bootstrap= True,n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=9, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.92\n",
      "Test score: 0.92\n"
     ]
    }
   ],
   "source": [
    "print('Train score: %.2f'%rnd.score(X_train_sm, y_train_sm))\n",
    "print('Test score: %.2f'%rnd.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6292735042735043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = rnd.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, rnd.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Gradient Boosting </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {'n_estimators':[100, 500 , 1000], \n",
    "              'learning_rate':[0.1, 0.5, 1 ],\n",
    "            'max_depth' : [1,2,3]}\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_grid = GridSearchCV(clf, param_grid = param_grid, cv = sk, n_jobs = -1, scoring = 'roc_auc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=GradientBoostingClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.5, 1], 'max_depth': [1, 2, 3],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_grid.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Best cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(gbc_grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(gbc_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=500, random_state=0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(max_depth = 3,n_estimators = 500, learning_rate=0.1, random_state=0,)\n",
    "gbrt.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.975\n",
      "Accuracy on test set: 0.945\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train_sm, y_train_sm)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6648212898212897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = gbrt.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, gbrt.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model ( 5 points)\n",
    "Explain which machine learning model is the best model for this dataset and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have run many models inorder to check the model which can fit the dataset well.\n",
    "Out of all those models, in the previous question, I found decision tree to be the best model.I have displayed the results of the following models:\n",
    "    \n",
    "   <b>  Gradient Boosting </b>\n",
    "   \n",
    "Accuracy on training set: 0.975\n",
    "Accuracy on test set: 0.945\n",
    "\n",
    "roc_auc_score:  0.6648212898212897\n",
    "    \n",
    "<b> RFC </b>\n",
    "\n",
    "roc_auc_score:  0.6292735042735043\n",
    "\n",
    "Train score: 0.92\n",
    "Test score: 0.92\n",
    "\n",
    "<b> PASTING WITH KNN </b>\n",
    "\n",
    "roc_auc_score:  0.7022144522144522\n",
    "\n",
    "Train score: 0.81\n",
    "Test score: 0.65\n",
    "\n",
    "<b> BAGGING WITH RANDOM FOREST </b>\n",
    "\n",
    "roc_auc_score:  0.6865773115773115\n",
    "\n",
    "Train score: 0.89\n",
    "Test score: 0.83\n",
    "\n",
    "<b> BAGGING WITH KNN </b>\n",
    "\n",
    "roc_auc_score:  0.7022144522144522\n",
    "\n",
    "Train score: 0.81\n",
    "Test score: 0.65\n",
    "\n",
    "<b> DECISION TREE </b>\n",
    "\n",
    "roc_auc_score:  0.7898212898212897\n",
    "\n",
    "Test_Score: 0.9122203098106713 Train Score 0.8809801633605601\n",
    "\n",
    "<b> SVC POLY </b> \n",
    "\n",
    "roc_auc_score:  0.6712315462315462\n",
    "\n",
    "Train Score 0.9760793465577596\n",
    "Test Score 0.9432013769363167\n",
    "\n",
    "<b> Logistic </b>\n",
    "\n",
    "roc_auc_score:  0.6417055167055168\n",
    "\n",
    "Train Score 0.954784130688448\n",
    "Test Score 0.9380378657487092\n",
    "\n",
    "<b> KNN </b>\n",
    "\n",
    "roc_auc_score:  0.7097902097902098\n",
    "\n",
    "Train score: 0.9504\n",
    "Test score: 0.9088\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the models I have run, i could get an highest roc_auc_score for - Decision Tree , KNN and Bagging with KNN.which is almost near to 0.70. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amongst all these models, Decision tree model has been confirmed to perform well with an roc_auc score of 0.789 and with an very minimum train and test scores difference.\n",
    "\n",
    "Test_Score: 0.9122203098106713 \n",
    "\n",
    "Train Score 0.8809801633605601\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.95\n",
      "Best parameters: {'max_depth': 9, 'min_samples': 10, 'min_samples_split': 450, 'min_impurity_decrease': 0.0002}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "best_score = 0\n",
    "for max_depth in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    for min_samples_leaf in [10,25,50,100,500,1000,250,1500,2000,750]:\n",
    "        for  min_samples_split in [10,50,100,150,200,250,300,350,400,450]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "            for min_impurity_decrease in [0.0002,0.0005,0.0007,0.0009,0.001,0.003,0.005,0.007,0.009,0.01]:\n",
    "                dtree = DecisionTreeClassifier(max_depth = max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split, random_state=0)\n",
    "                dtree.fit(X_train_sm, y_train_sm)\n",
    "        # evaluate the SVC on the test set\n",
    "                score = dtree.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'max_depth': max_depth, 'min_samples': min_samples_leaf,'min_samples_split': min_samples_split, 'min_impurity_decrease':min_impurity_decrease}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Score: 0.9122203098106713 Train Score 0.8809801633605601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(max_depth = 9,min_samples_leaf = 10,min_impurity_decrease = 0.0002,min_samples_split = 300,random_state=0)\n",
    "dtree.fit(X_train_sm, y_train_sm)\n",
    "Test_Score = dtree.score(X_test, y_test)\n",
    "Train_score = dtree.score(X_train_sm, y_train_sm)\n",
    "print('Test_Score:', Test_Score, 'Train Score',Train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.7898212898212897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = dtree.predict(X_test)\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, dtree.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading (50 points)\n",
    "Your model should predict the outcome for every row in the test.csv. \n",
    "You should be able to correctly print the ``final_test_prediction`` executing the following statement: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_prediction = dtree.predict(df1)\n",
    "final_test_prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
